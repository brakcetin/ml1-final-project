\label{sec:method_burak}

In this approach, we investigated the trade-off between dimensionality reduction and classification accuracy. The primary objective was to design a computationally efficient pipeline suitable for embedded devices by compressing the feature space while maintaining high predictive performance.

\subsubsection{Data Preprocessing and PCA}
Principal Component Analysis (PCA) is inherently sensitive to the scale of input features. Since the UCI HAR dataset contains features with varying ranges, we first applied Z-Score normalization to standardize all 561 features to zero mean and unit variance:
\begin{equation}
    z = \frac{x - \mu}{\sigma}
\end{equation}
Following normalization, PCA was applied with a cumulative variance threshold of \textbf{95\%}. This process reduced the original 561 dimensions to \textbf{102 principal components}, achieving an \textbf{81.8\% compression rate}. This significant reduction drastically lowers the computational cost for subsequent training steps.

\subsubsection{Model Optimization}
We trained four distinct classifiers on the reduced feature space using 10-Fold Stratified Cross-Validation (CV) to ensure robustness. The hyperparameter tuning yielded the following optimal configurations:

\begin{itemize}
    \item \textbf{Artificial Neural Network (ANN):} A multi-layer perceptron with two hidden layers ([200, 100] neurons) achieved the highest individual CV accuracy (97.31\%).
    \item \textbf{Support Vector Machine (SVM):} Optimized with a \textit{Linear Kernel} and $C=1.0$, demonstrating that the PCA-transformed space is linearly separable (CV: 97.23\%).
    \item \textbf{k-Nearest Neighbors (kNN):} The best performance was observed at $k=1$ (CV: 96.54\%), though this suggests potential susceptibility to noise (overfitting).
    \item \textbf{Decision Tree (DT):} Achieved only 84.47\% CV accuracy. The poor performance is attributed to PCA's feature rotation, which disrupts the axis-aligned splits required by decision trees.
\end{itemize}

\subsubsection{Ensemble Strategy}
To mitigate individual model biases—specifically the overfitting of kNN and the decision boundaries of SVM—we constructed a \textbf{Voting Ensemble} comprising the top three models (ANN, SVM, and kNN). The ensemble aggregates predictions using majority voting to improve generalization on unseen subjects.

\subsubsection{Performance Analysis}
The models were evaluated on the strictly separated Test Set. To visualize the comparative performance, we computed accuracy metrics across all models, as illustrated in Figure~\ref{fig:model_comparison}. The quantitative results are detailed in Table~\ref{tab:burak_results}, which compares the cross-validation (CV) and testing phases.

% --- FIGURE 1: MODEL COMPARISON ---
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/model_comparison.png}
    \caption{Test Accuracy Comparison. The Ensemble model outperforms individual classifiers.}
    \label{fig:model_comparison}
\end{figure}

% --- TABLE 1: PERFORMANCE RESULTS ---
\begin{table}[h]
  \caption{Performance Comparison (PCA Approach)}
  \label{tab:burak_results}
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{lccc}
    \toprule
    Model & CV Accuracy & Test Accuracy & F1-Score\\
    \midrule
    \textbf{Ensemble} & \textbf{-} & \textbf{93.32\%} & \textbf{0.9329} \\
    ANN & 97.31\% & 93.04\% & 0.9302 \\
    SVM & 97.23\% & 92.20\% & 0.9216 \\
    kNN ($k=1$) & 96.54\% & 84.39\% & 0.8437 \\
    Decision Tree & 84.47\% & 78.38\% & 0.7836 \\
    \bottomrule
  \end{tabular}%
  }
\end{table}

While the individual kNN model suffered a significant drop in testing (indicating overfitting due to $k=1$), the \textbf{Ensemble model} successfully compensated for this, achieving the highest overall accuracy of \textbf{93.32\%}.

To analyze the specific error patterns, we examined the Confusion Matrix shown in Figure~\ref{fig:ensemble_cm}. The matrix reveals that the model is highly robust, yet slight confusions exist between static activities. To further validate this, Table~\ref{tab:class_performance} presents the detailed precision and recall values for each class.

% --- FIGURE 2: CONFUSION MATRIX ---
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/ensemble_cm.png}
    \caption{Confusion Matrix of the Ensemble Model. Note the slight confusion between Sitting and Standing.}
    \label{fig:ensemble_cm}
\end{figure}

% --- TABLE 2: CLASS PERFORMANCE ---
\begin{table}[h]
  \caption{Per-Class Performance of the Best Model (Ensemble)}
  \label{tab:class_performance}
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{lcccc}
    \toprule
    \textbf{Activity} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
    \midrule
    Standing & 0.8696 & 0.9530 & 0.9094 & 532 \\
    Sitting & 0.9350 & 0.8493 & 0.8901 & 491 \\
    Laying & 0.9981 & 0.9888 & 0.9935 & 537 \\
    Walking & 0.9363 & 0.9778 & 0.9566 & 496 \\
    Walk Down & 0.9409 & 0.9095 & 0.9249 & 420 \\
    Walk Up & 0.9264 & 0.9087 & 0.9175 & 471 \\
    \midrule
    \textit{Weighted Avg} & & & \textbf{93.32\%} & \textbf{2947} \\
    \bottomrule
  \end{tabular}%
  }
\end{table}

\subsubsection{Limitations and Future Work}
As confirmed by the confusion matrix, misclassifications primarily occurred between \textit{Sitting} and \textit{Standing}. Since PCA transforms the feature space, the explicit vertical orientation signal (gravity-z) may have been diluted. Future improvements include:
\begin{enumerate}
    \item \textbf{Explicit Gravity Injection:} Concatenating the raw `tGravityAcc-mean()-Z` feature with PCA components to restore orientation data.
    \item \textbf{k-Value Optimization:} Increasing $k$ (e.g., to 7) in kNN to improve generalization on unseen subjects.
\end{enumerate}
