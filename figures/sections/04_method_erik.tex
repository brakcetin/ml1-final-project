\subsubsection{Dataset Quality Challenges and Initial Attempts}

One of the major limitations repeatedly highlighted in recent HAR literature is the lack of a truly
high–quality, general-purpose benchmark dataset. As noted in prior research, most publicly
available datasets suffer from limited or imbalanced data, small sample sizes, and activity sets
that do not capture the diversity and complexity of real human behaviour~\cite{ref33}. Many
existing benchmarks contain simplistic motions and short, well-structured sequences, which
do not reflect realistic daily variability. Furthermore, deep learning architectures that rely
on contextual information often struggle to integrate such limited or biased data~\cite{ref41}.
Although these models may achieve state-of-the-art accuracy on benchmark datasets,
they frequently exhibit \emph{overconfidence} in their predictions, indicating a lack of
generalisation.

In the early stages of this work, we explored whether the quality and representativeness of HAR
datasets could be improved either by \emph{simplifying} the feature space while preserving its
semantic meaning or by \emph{enriching} the existing raw signals. One natural idea was to
address class imbalance directly. Given the distribution observed in our datasets, techniques
such as SMOTE appeared promising—particularly for activities such as \textit{Walking},
where additional synthetic samples could better populate the high-dimensional sensor
space. Figure~\ref{fig:smote_distribution} illustrates the imbalance structure and the potential
benefit of interpolation in unexplored regions of the feature manifold.

% FIGURE PLACEHOLDER
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/smote.png}
    \caption{Example of class imbalance and the potential effect of SMOTE on the \textit{Walking} class.}
    \label{fig:smote_distribution}
\end{figure}

Ultimately, however, SMOTE was discarded due to time constraints and because a more
promising direction emerged: \textbf{merging multiple HAR datasets}. We experimented with
combining the raw signals from the UCI HAR and WISDM datasets, starting from their raw
accelerometer and gyroscope measurements. A methodological mistake made in the first
attempt was to analyse their joint distribution \emph{after} preprocessing rather than at the raw
signal level—an important lesson for future cross-dataset integration.

Principal Component Analysis (PCA) suggested that the joint space was surprisingly coherent:
the two datasets overlapped reasonably well, as shown in Fig.~\ref{fig:pca_merge}. However,
a nonlinear projection using t-SNE revealed the opposite behaviour: the distributions
separated sharply, indicating clear differences in movement patterns, device placement,
sensor noise, or subject behaviour.

% FIGURE PLACEHOLDER
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/pcaNoSeparable.png}
    \caption{PCA projection of merged HAR and WISDM raw datasets shows partial overlap.}
    \label{fig:pca_merge}
\end{figure}

% FIGURE PLACEHOLDER
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tsneNoSeparable.png}
    \caption{t-SNE projection of merged HAR and WISDM raw datasets shows partial overlap.}
    \label{fig:tsne_norm}
\end{figure}

To mitigate this gap, we evaluated \textbf{per-subject normalisation}. The intuition is that people
move differently, and devices differ across subjects. By aligning distributions so that each
subject shares a similar covariance structure, we observed noticeably more optimistic results,
as illustrated in Fig.~\ref{fig:tsne_norm}. These results suggest that domain alignment at the
subject level can significantly reduce dataset shift, even without complex domain-adaptation
methods.

% FIGURE PLACEHOLDER
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tsneSeparable87.png}
    \caption{t-SNE projection after per-subject normalisation shows improved cross-dataset alignment.}
    \label{fig:tsne_norm}
\end{figure}

Although more advanced techniques such as Domain-Adversarial Neural Networks (DANN)
are common in academic work, they were excluded from this study due to the requirement
for real-time processing and interpretability. Our experiments reinforce what we believe
remains one of the central research gaps in HAR today: \textbf{the absence of a universal,
cross-subject, cross-device, cross-environment dataset}. Real-world HAR systems must still
be tailored to the specific sensor, device, and population being monitored. This limitation is a
primary barrier to producing robust, deployable, and generalisable HAR models.

\subsubsection{AutoEncoder--LDA Representation Learning Approach}

To address the limitations imposed by heterogeneous raw sensor distributions, we explored a 
representation-learning strategy based on an AutoEncoder followed by Linear Discriminant 
Analysis (LDA). This approach was motivated by recent results showing that encoder--decoder 
architectures can preserve semantic structure while providing compact embeddings suitable for 
classification. In particular, Zhang~et~al.~\cite{ref34} demonstrated the effectiveness of 
U-Net encoder/decoder mechanisms for extracting meaningful latent representations while 
maintaining spatial (or temporal) consistency. Inspired by this, we adopted an AutoEncoder 
architecture to compress the windowed HAR signals into a 64-dimensional embedding.

The rationale for using an AutoEncoder was threefold:

\begin{itemize}
    \item \textbf{Semantic preservation:} unlike purely linear dimensionality reduction, the encoder learns a 
    nonlinear manifold that reflects the structure of human motion---important for HAR tasks.

    \item \textbf{Efficient compression:} reducing each window to 64 features lowers computational cost and 
    enables lightweight classifiers suitable for real-time inference.

    \item \textbf{Future extensibility:} an explicit latent space opens the possibility of using 
    Variational Component Analysis (VCA) or generative models to synthesize missing data or 
    rebalance underrepresented classes. Although this direction was considered, it was discarded 
    due to time constraints.
\end{itemize}

After training the AutoEncoder, each window is represented by a 64-dimensional embedding 
vector:
\[
\mathbf{e} = (emb_1, emb_2, \dots, emb_{64}).
\]
These embeddings serve as the input to the subsequent classification stage.


Before applying LDA, we analysed the statistical shape of each latent dimension produced by 
the AutoEncoder. Although the encoder provides a compact representation, the resulting 
embeddings do not necessarily follow a Gaussian-like distribution. In practice, many 
dimensions exhibited high skewness and heavy-tailed behaviour, which may hinder linear 
methods such as LDA.

To stabilise the distribution of the embeddings, we adopted an \textbf{adaptive normalisation 
strategy}. The idea is to select the most appropriate normalisation method \emph{per feature} 
based on its empirical distribution:

\begin{itemize}
    \item If the embedding dimension showed \textbf{low skewness} and \textbf{kurtosis close to 3} 
    (i.e., approximately Gaussian), we applied \textbf{Z-score normalisation}.  
    This transformation centres the feature and rescales it to unit variance, which is ideal for 
    dimensions that already follow a symmetric, bell-shaped distribution.

    \item If the dimension exhibited \textbf{high skewness} or \textbf{heavy tails}, we applied 
    \textbf{Min--Max scaling}.  
    This transformation maps the feature into the range \([0,1]\), preserving the relative ordering 
    while preventing extreme values from disproportionately influencing the classifier.
\end{itemize}

The criteria allow the system to normalise each embedding coordinate according to its 
distributional nature:  
\[
\text{Approximately Gaussian} \;\Rightarrow\; \text{Z-score}, \qquad
\text{Non-Gaussian or heavy-tailed} \;\Rightarrow\; \text{Min--Max}.
\]

This adaptive strategy reduces distortions caused by asymmetric or heavy-tailed features, makes 
the latent space more homogeneous, and improves the effectiveness of the subsequent LDA 
projection. In practice, this resulted in a more stable embedding geometry and clearer 
class separation after the discriminant projection.

\subsubsection{LDA on Learned Embeddings}

To improve class separability, we applied Linear Discriminant Analysis (LDA) on the learned 
embeddings. LDA seeks a linear combination of the embedding dimensions that maximises the 
ratio between inter-class and intra-class variance. Formally, it finds a projection matrix 
\(\mathbf{W}\) such that:
\[
\mathbf{W} = \arg\max_{\mathbf{W}} 
\frac{\mathbf{W}^\top S_B \mathbf{W}}{\mathbf{W}^\top S_W \mathbf{W}},
\]
where \(S_B\) and \(S_W\) denote the between-class and within-class scatter matrices, respectively.

Applying LDA after the AutoEncoder has two advantages:

\begin{enumerate}
    \item It enhances discriminative structure already present in the latent representations.
    \item It reduces the dimensionality further to \(C-1\) components, where \(C\) is the number of activities.
\end{enumerate}

This two-stage pipeline (nonlinear compression followed by linear discriminant projection) has 
proved effective in HAR classification, particularly when datasets differ in distribution.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/Proyeccion LD1.png}
    \caption{Proyection in LD1 and LD2 vectors}
    \label{fig:tsne_norm}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/densidad.png}
    \caption{Density for each class in LD1 vector}
    \label{fig:tsne_norm}
\end{figure}
